{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root:INFO]:starting (cellevents.py:36, time=14:27)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.2 ms\n"
     ]
    }
   ],
   "source": [
    "from maskmm.ipstartup import *\n",
    "import os\n",
    "import glob\n",
    "from os.path import join\n",
    "import random\n",
    "import torch\n",
    "\n",
    "import skimage.io\n",
    "from skimage.io import imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from maskmm.models.maskrcnn import MaskRCNN\n",
    "from maskmm import learner\n",
    "from maskmm.utils import visualize\n",
    "\n",
    "from maskmm.datasets.nuke.config import Config\n",
    "from maskmm.datasets.nuke.dataset import Dataset\n",
    "\n",
    "ROOT_DIR = \"/home/ubuntu/maskmm\"\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"data/models/mask_rcnn_coco.pth\")\n",
    "DATA = join(expanduser(\"~\"), \"data\", \"nuke\") \n",
    "\n",
    "config = Config()\n",
    "config.STEPS_PER_EPOCH = 1\n",
    "config.VALIDATION_STEPS = 1\n",
    "torch.manual_seed(123)\n",
    "random.seed(123)\n",
    "torch.cuda.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root:INFO]:starting (cellevents.py:36, time=14:27)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.04 ms\n"
     ]
    }
   ],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root:INFO]:starting (cellevents.py:36, time=14:27)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train    505\n",
       "valid    123\n",
       "Name: subset, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 40.1 ms\n"
     ]
    }
   ],
   "source": [
    "# create validation sample\n",
    "np.random.seed(0)\n",
    "pvalid = .2\n",
    "trainpath = join(DATA, \"stage1_train\")\n",
    "\n",
    "df = pd.DataFrame(os.listdir(trainpath), columns=[\"image\"])\n",
    "df[\"subset\"] = np.random.random(len(df))>pvalid\n",
    "df.loc[df.subset==True, \"subset\"] = \"train\"\n",
    "df.loc[df.subset==False, \"subset\"] = \"valid\"\n",
    "df.to_pickle(join(DATA, \"subset.pkl\"))\n",
    "df.subset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root:INFO]:starting (cellevents.py:36, time=14:27)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 109 ms\n"
     ]
    }
   ],
   "source": [
    "dataset_train = Dataset(config)\n",
    "dataset_train.load_nuke(trainpath, \"train\")\n",
    "dataset_train.prepare()\n",
    "\n",
    "dataset_val = Dataset(config)\n",
    "dataset_val.load_nuke(trainpath, \"valid\")\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root:INFO]:starting (cellevents.py:36, time=14:27)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.21 ms\n"
     ]
    }
   ],
   "source": [
    "%%s\n",
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root:INFO]:starting (cellevents.py:36, time=14:27)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.97 s\n"
     ]
    }
   ],
   "source": [
    "model = MaskRCNN(model_dir=MODEL_DIR, config=config)\n",
    "model.initialize_weights()\n",
    "\n",
    "# load pretrained except final layers that depend on NUM_CLASSES\n",
    "params = torch.load(COCO_MODEL_PATH)\n",
    "params.pop('classifier.linear_class.weight')\n",
    "params.pop(\"classifier.linear_bbox.weight\")\n",
    "params.pop(\"mask.conv5.weight\")\n",
    "params.pop('classifier.linear_class.bias')\n",
    "params.pop(\"classifier.linear_bbox.bias\")\n",
    "params.pop(\"mask.conv5.bias\")\n",
    "model.load_state_dict(params, strict=False)\n",
    "if config.GPU_COUNT:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root:INFO]:starting (cellevents.py:36, time=14:27)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 1. LR=0.01\n",
      "\n",
      "Checkpoint Path: /home/ubuntu/maskmm/logs/dsb201810%d_1427/mask_rcnn_dsb_{:04d}.pth\n",
      "Epoch 1/1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root:INFO]:tensor([[[[ 104.3000,  104.3000,  109.3000,  ...,  102.3000,\n",
      "            101.3000,  106.3000],\n",
      "          [  98.3000,  102.3000,  108.3000,  ...,   96.3000,\n",
      "            103.3000,  108.3000],\n",
      "          [ 108.3000,  111.3000,  105.3000,  ...,  104.3000,\n",
      "            100.3000,   99.3000],\n",
      "          ...,\n",
      "          [ 102.3000,  105.3000,  103.3000,  ...,   65.3000,\n",
      "             60.3000,   53.3000],\n",
      "          [ 105.3000,  107.3000,  101.3000,  ...,   59.3000,\n",
      "             55.3000,   51.3000],\n",
      "          [ 101.3000,  106.3000,  104.3000,  ...,   54.3000,\n",
      "             52.3000,   51.3000]],\n",
      "\n",
      "         [[ 111.2000,  111.2000,  116.2000,  ...,  109.2000,\n",
      "            108.2000,  113.2000],\n",
      "          [ 105.2000,  109.2000,  115.2000,  ...,  103.2000,\n",
      "            110.2000,  115.2000],\n",
      "          [ 115.2000,  118.2000,  112.2000,  ...,  111.2000,\n",
      "            107.2000,  106.2000],\n",
      "          ...,\n",
      "          [ 109.2000,  112.2000,  110.2000,  ...,   72.2000,\n",
      "             67.2000,   60.2000],\n",
      "          [ 112.2000,  114.2000,  108.2000,  ...,   66.2000,\n",
      "             62.2000,   58.2000],\n",
      "          [ 108.2000,  113.2000,  111.2000,  ...,   61.2000,\n",
      "             59.2000,   58.2000]],\n",
      "\n",
      "         [[ 124.1000,  124.1000,  129.1000,  ...,  122.1000,\n",
      "            121.1000,  126.1000],\n",
      "          [ 118.1000,  122.1000,  128.1000,  ...,  116.1000,\n",
      "            123.1000,  128.1000],\n",
      "          [ 128.1000,  131.1000,  125.1000,  ...,  124.1000,\n",
      "            120.1000,  119.1000],\n",
      "          ...,\n",
      "          [ 122.1000,  125.1000,  123.1000,  ...,   85.1000,\n",
      "             80.1000,   73.1000],\n",
      "          [ 125.1000,  127.1000,  121.1000,  ...,   79.1000,\n",
      "             75.1000,   71.1000],\n",
      "          [ 121.1000,  126.1000,  124.1000,  ...,   74.1000,\n",
      "             72.1000,   71.1000]]]], device='cuda:0') (resnetFPN.py:51, time=14:27)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn.functional' has no attribute 'smooth_l1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-577f3816a60a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create model in training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"heads\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/maskmm/maskmm/learner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, learning_rate, epochs, layers)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_bn_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/maskmm/maskmm/learner.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self, datagenerator, steps)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;31m# Compute losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mrpn_class_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrpn_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpn_class_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mrpn_bbox_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrpn_bbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpn_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpn_pred_bbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mmrcnn_class_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrcnn_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_class_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmrcnn_class_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mmrcnn_bbox_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrcnn_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_deltas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmrcnn_bbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/maskmm/maskmm/loss.py\u001b[0m in \u001b[0;36mrpn_bbox\u001b[0;34m(target_bbox, rpn_match, rpn_bbox)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# Smooth L1 loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth_l1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrpn_bbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_bbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn.functional' has no attribute 'smooth_l1'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "# Create model in training mode\n",
    "learner = learner.Learner(model, dataset_train, dataset_val)\n",
    "learner.train(.01, 1, \"heads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Which weights to start with?\n",
    "init_with = \"last\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last()[1], by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=.001, \n",
    "            epochs=10, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=.001,\n",
    "            epochs=30, \n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "# model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
    "# model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Predict on valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class InferenceConfig(nuke.NukeConfig):\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()[1]\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "image_id = 26 #random.choice(dataset_val.image_ids)\n",
    "print(image_id)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "def score(image_ids, verbose=False):\n",
    "    \"\"\" return mean average precision across range of IOU thresholds\n",
    "    NOTE: takes 3 minutes for 10 using P2 on 1024*1023\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for image_id in tqdm(image_ids):\n",
    "        # y_true mask\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "            modellib.load_image_gt(dataset_val, inference_config,\n",
    "                                   image_id, use_mini_mask=False)\n",
    "        y_true = [gt_mask[:, :, i] for i in range(gt_mask.shape[2])]\n",
    "\n",
    "        # y_pred\n",
    "        results = model.detect([image], verbose=0)\n",
    "        masks = results[0][\"masks\"]\n",
    "        \n",
    "        masks = nuke.remove_overlaps(masks)\n",
    "        \n",
    "        # convert\n",
    "        y_pred = [masks[:, :, i] for i in range(masks.shape[2])]\n",
    "\n",
    "        # score\n",
    "        if len(masks) == 0:\n",
    "            score = 0\n",
    "        else:\n",
    "            score = nuke.score_image(y_true, y_pred, verbose)\n",
    "        #log((image_id, score))\n",
    "        scores.append(score)\n",
    "    return np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "score([36], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "score(dataset_val.image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = nuke.NukeDataset()\n",
    "dataset_test.load_nuke(datapath, \"stage1_test\")\n",
    "dataset_test.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check a random image from test set\n",
    "image_id = 40 #random.choice(dataset_test.image_ids)\n",
    "image = dataset_test.load_image(image_id)\n",
    "results = model.detect([image], verbose=1)\n",
    "r = results[0]\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare output for submission\n",
    "out = []\n",
    "for image_id in dataset_test.image_ids:\n",
    "    source_id = dataset_test.image_info[image_id][\"id\"]\n",
    "    image = dataset_test.load_image(image_id)\n",
    "    results = model.detect([image], verbose=0)\n",
    "    masks = results[0][\"masks\"]\n",
    "    masks = nuke.remove_overlaps(masks)\n",
    "    rles = [nuke.rle_encoding(masks[:,:,m]) for m in range(masks.shape[2])]\n",
    "    for rle in rles:\n",
    "        out.append(dict(ImageId=source_id, EncodedPixels=rle))\n",
    "df = pd.DataFrame(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.ImageId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# na mask after overlaps removed\n",
    "df=df[[\"ImageId\", \"EncodedPixels\"]].dropna()\n",
    "df.to_csv(\"out.csv\", index=False)\n",
    "pd.read_csv(\"out.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "df.ImageId.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
